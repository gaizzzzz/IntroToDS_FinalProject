{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color: #0A6EBD; font-family: 'Trebuchet MS', Arial, sans-serif; color: white; padding: 20px; font-size: 40px; font-weight: bold; border-radius: 0 0 0 0; box-shadow: 0px 6px 8px rgba(0, 0, 0, 0.2);\">\n",
    "  Lab 02 - Introduction To Data Science @ FIT-HCMUS, VNU-HCM ðŸ“Œ\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color: #5A96E3; font-family: 'Trebuchet MS', Arial, sans-serif; color: white; padding: 20px; font-size: 40px; font-weight: bold; border-radius: 0 0 0 0; box-shadow: 0px 6px 8px rgba(0, 0, 0, 0.2);\">\n",
    "  Stage 00 - A brief introduction to course assignment 2ðŸ“Œ\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generic workflow stages, however there are use cases with exceptions.\n",
    "1. Overview: \n",
    "    - Project title.\n",
    "    - What are the goals of the project (question or problem definition)?\n",
    "    - What is(are) dataset(s) ?\n",
    "    - Describe your team members.\n",
    "2. Data overview\n",
    "    - What is the source of data? Public? Crawled?\n",
    "    - What is the size of data?\n",
    "    - Brief introduction of data? What is the mean of each data properties?\n",
    "3. Data preparation and cleaning\n",
    "    - Acquire training and testing data.\n",
    "    - Wrangle, prepare, cleanse the data.\n",
    "    - Missing value treatment.\n",
    "    - Outlier detection and treatment.\n",
    "    - Feature engineering.\n",
    "4. Exploratory data analysis: Analyze, identify patterns, and explore the data.\n",
    "    - Univariate analysis.\n",
    "    - Bivariate analysis.\n",
    "    - Multivariate analysis.\n",
    "5. Data visualization\n",
    "    - Graphs, plots.\n",
    "    - Describe insights derivered from the visuals (combine with outside information from dataset that you found).\n",
    "6. Hypothesis testing and insights\n",
    "    - Statistical tests used\n",
    "    - Findings and insights\n",
    "7. Final report and presentation\n",
    "    - Key findings.\n",
    "    - What are limitations of the analysis?\n",
    "    - Propose recommendations for the next steps.\n",
    "8. References and data sources\n",
    "    - Structure dataset(s) and export links.\n",
    "    - Listing research papers or articles in reference section.\n",
    "9. Project structurization\n",
    "    - Notebooks source codes\n",
    "    - Python source codes\n",
    "    - Model binary files\n",
    "    - Data files\n",
    "    - Presentation or report files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data science solutions workflow solves for <font color=lightgreen>seven major goals (7C)</font>.\n",
    "\n",
    "<font color=lightgreen>**Classifying**</font>: Classifying involves classifying or categorizing data into different classes or categories. It's often used in classification problems where you aim to assign a label or category to data points. We may also want to understand the implications or correlation of different classes with our solution goal.\n",
    "\n",
    "<font color=lightgreen>**Correlating**</font>: Considering the available features within the training dataset, one wants to identify and analyse the relationships between them, and then determine which features within the dataset significantly contribute to our solution goal. Generally, correlating refers to the process of identifying and analysing relationships or correlations between different variables in the data. This step helps understand how variables are related to each other and is often part of exploratory data analysis (EDA). Correlating certain features may help in creating, completing, or correcting features.\n",
    "\n",
    "<font color=lightgreen>**Converting**</font>: In the data modelling stage, one should prepare the data to satisfy the requirements of learning algorithms. Converting data may involve changing the format or data type of variables to make them compatible with the analysis or modelling techniques. For example, converting text data into numerical features using techniques like one-hot encoding.\n",
    "\n",
    "<font color=lightgreen>**Completing**</font>: Due to many reasons, such as weak data collection techniques or low-quality data resources, datasets often have the imcompleteness characteristic. Completing the data involves addressing missing values in the dataset. Missing data can impact the quality of analysis and modelling, so it's important to handle missing values through imputation or other techniques.\n",
    "\n",
    "<font color=lightgreen>**Correcting**</font>: We may also search for errors or wrong values within features in the given training dataset and either confirm these values or reject the samples that include the errors. The process of finding and repairing faults or inconsistencies in a dataset is known as data rectification. Looking for outliers in our samples or attributes is one way. Another alternative is to eliminate a characteristic if it does not contribute to the analysis or has the potential to significantly affect the results.\n",
    "\n",
    "<font color=lightgreen>**Creating**</font>: Feature engineering or simply creating is a critical phase in the data science pipeline for creating new features or variables. It entails creating new variables or modifying existing ones in order to improve the performance of machine learning models.\n",
    "\n",
    "<font color=lightgreen>**Charting**</font>: Charting and data visualisation are critical components of the data science workflow. It entails producing charts, graphs, and other visual representations of data in order to better analyse patterns, trends, and insights. Data visualisation may help with communication and narrative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment is an extended version of Assignment 1. The main purpose here is to make an exploratory analysis of the demographic and socio-economic data provided by the World Bank. Thus, this assignment will lead a brief introduction to the data science process for students who have enrolled in the Introduction to Data Science course 2023 at FIT-HCM, VNU-HCM. After success in crawling data using the Web API (http://api.worldbank.org/v2/country/all/indicator/SP.POP.TOTL) in Assignment 1, Once again, you will have to crawl data by using this API, but on another scale.\n",
    "\n",
    "1. You will learn how to setup a data science project. How do you structure it as clearly as possible?\n",
    "2. You will learn basic techniques in data pre-processing, basic exploratory data analysis (EDA) from making questions and finding the answer from insights developed from statistical methods, and simple visualisation methods.\n",
    "3. You will learn to set up a report clearly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up your coding environment with Anaconda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you should [download and install Anaconda](https://www.anaconda.com/download) for your operating systems. Then, starting install your development environment using ```requirements.txt```. \n",
    "\n",
    "**Note**: Suppose that you want to use Python 3.9, I built this requirement packages list base on Python 3.9. So if you want to install these packages in other Python version, please check all packages again via command ```conda search -c conda-forge -f  <package name>``` to verify the version of each package and change it in ```requirements.txt``` file. \n",
    "\n",
    "```bash\n",
    "# create conda virtual environment\n",
    "conda create --name min_ds-env python=3.9 -y\n",
    "\n",
    "# activate created conda virtual environment\n",
    "conda activate min_ds-env\n",
    "\n",
    "# install dependencies\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to complete this assignment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will do your assignment directly in this notebook. First, fill in your name and ID at the beginning of the file. In the notebook, fill in places that say:\n",
    "```python\n",
    "#TODO\n",
    "```\n",
    "\n",
    "During your work, you can print out the result, create more cells to test, or create more functions to handle things. Please note that <font color=red>you are not allowed to delete or modify my code cells</font> (except in the case that mentioned above). Let remove `raise NotImplementedError(\"not implement\")` when running code.\n",
    "\n",
    "Always press `Ctrl + S` in order to save your work.\n",
    "\n",
    "**Notes:** \n",
    "\n",
    "    *  Copy means zero\n",
    "    *  You have to submit your work on time. No exception\n",
    "    *  Any questions about your grade are based on the assignment submitted on Moodle\n",
    "    *  Wrong submission takes you -2 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to submit this assignment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When grading your assignment, I will choose `Kernel` - `Restart Kernel & Run All Cells` in order to restart the kernel and run all cells in your notebook. Therefore, you should do that before submitting to ensure that the outputs are all as expected.\n",
    "\n",
    "After that, you make a submited direction as follow:\n",
    "\n",
    "- Folder `StudentCode` (e.g. If your student code is 1234567, then your folder is `1234567`)\n",
    "\n",
    "Finally, you compress your folder (`StudentCode`) and submit on Moodle. **The extension of the file is nothing else but `.zip`.**\n",
    "\n",
    "<font color=red>Please strictly follow the submission rules.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laboratory structure explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab project structure is built under the [Cookiecutter Data Science](https://github.com/drivendata/cookiecutter-data-science) - A logical, reasonably standardized, but flexible project structure for doing and sharing data science work. \n",
    "\n",
    "```\n",
    "â”œâ”€â”€ LICENSE-CC-BY-NC-ND-4.0.md\n",
    "â”œâ”€â”€ min_ds-env.yml\n",
    "â”œâ”€â”€ Makefile                 <- Makefile with commands like `make data` or `make train`\n",
    "â”œâ”€â”€ README.md                <- The top-level README for developers using this project.\n",
    "â”œâ”€â”€ data\n",
    "â”‚   â”œâ”€â”€ external             <- Data from third party sources.\n",
    "â”‚   â”œâ”€â”€ interim              <- Intermediate data that has been transformed.\n",
    "â”‚   â”œâ”€â”€ processed            <- The final, canonical data sets for modeling.\n",
    "â”‚   â””â”€â”€ raw                  <- The original, immutable data dump.\n",
    "â”‚\n",
    "â”‚\n",
    "â”œâ”€â”€ models                   <- Trained and serialized models, model predictions, or model summaries\n",
    "â”‚\n",
    "â”œâ”€â”€ notebooks                <- Jupyter notebooks. Naming convention is a number (for ordering),\n",
    "â”‚                               the creator's initials, and a short `-` delimited description, e.g.\n",
    "â”‚                               `1.0-initial-data-exploration`.\n",
    "â”‚\n",
    "â”œâ”€â”€ references                <- Data dictionaries, manuals, and all other explanatory materials.\n",
    "â”‚\n",
    "â”œâ”€â”€ reports                   <- Generated analysis as HTML, PDF, LaTeX, etc. or your written by template such as https://github.com/Wandmalfarbe/pandoc-latex-template\n",
    "â”‚   â””â”€â”€ figures               <- Generated graphics and figures to be used in reporting\n",
    "â”‚\n",
    "â”œâ”€â”€ requirements.txt          <- The requirements file for reproducing the analysis environment\n",
    "â”‚\n",
    "â”œâ”€â”€ src                       <- Source code for use in this project.\n",
    "â”‚   â”œâ”€â”€ __init__.py           <- Makes src a Python module\n",
    "â”‚   â”‚\n",
    "â”‚   â”œâ”€â”€ data_module           <- Scripts to download or generate data\n",
    "â”‚   â”‚   â””â”€â”€ make_dataset.py\n",
    "â”‚   â”‚\n",
    "â”‚   â”œâ”€â”€ features_module       <- Scripts to turn raw data into features for modeling\n",
    "â”‚   â”‚   â””â”€â”€ build_features.py\n",
    "â”‚   â”‚\n",
    "â”‚   â”œâ”€â”€ models_module         <- Scripts to train models and then use trained models to make\n",
    "â”‚   â”‚   â”‚                        predictions\n",
    "â”‚   â”‚   â”œâ”€â”€ predict_model.py\n",
    "â”‚   â”‚   â””â”€â”€ train_model.py\n",
    "â”‚   â”‚\n",
    "â”‚   â””â”€â”€ visualization_module  <- Scripts to create exploratory and results oriented visualizations\n",
    "â”‚       â””â”€â”€ visualize.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contact information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have any concerns with this assignment, please write an email and send it to class lecturer or laboratory instructor in order to get useful advices\n",
    "- Class lecturer: **Le Ngoc Thanh** (lnthanh@fit.hcmus.edu.vn)\n",
    "- Course laboratory instructor: **Le Nhut Nam** (lenam.fithcmus@gmail.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LICENSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab 02 - Introduction To Data Science/ CSC14119 Â© 2023 by Department of Computer Science, Faculty of Information Technology, University of Science, Vietnam National University, Ho Chi Minh City is licensed under Attribution-NonCommercial-NoDerivatives 4.0 International\n",
    "\n",
    "Please read the file ```LICENSE-CC-BY-NC-ND-4.0.md``` for more understanding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
